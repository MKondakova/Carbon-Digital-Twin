{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступность CUDA: True\n",
      "Количество доступных устройств: 1\n",
      "Текущее устройство: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Доступность CUDA:\", torch.cuda.is_available())\n",
    "print(\"Количество доступных устройств:\", torch.cuda.device_count())\n",
    "print(\"Текущее устройство:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = [\n",
    "    { 'input_size': 8, 'hidden_size': 20, 'hidden_size_two': 60, 'hidden_size_three': 30, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 64, 'hidden_size_three': 12, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 32, 'hidden_size_two': 128, 'hidden_size_three': 64, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 64, 'hidden_size_two': 64, 'hidden_size_three': 64, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 8, 'hidden_size_two': 64, 'hidden_size_three': 32, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 16, 'hidden_size_three': 16, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2 * 10**6},\n",
    "    \n",
    "    { 'input_size': 8, 'hidden_size': 20, 'hidden_size_two': 60, 'hidden_size_three': 30, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 64, 'hidden_size_three': 12, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.01, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 32, 'hidden_size_two': 128, 'hidden_size_three': 64, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.0012, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 64, 'hidden_size_two': 64, 'hidden_size_three': 64, 'output_size': 1,\n",
    "    'num_epochs': 200, 'learning_rate': 0.0001, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 8, 'hidden_size_two': 64, 'hidden_size_three': 32, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2 * 10**6},\n",
    "    { 'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 16, 'hidden_size_three': 16, 'output_size': 1,\n",
    "    'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2 * 10**6},\n",
    "]\n",
    "\n",
    "name_models = ['MLv1', 'MLv2', 'MLv3', 'MLv4', 'MLv5', 'MLv6', 'MLv7', 'MLv8', 'MLv9', 'MLv10', 'MLv11', 'MLv12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLv1 {'input_size': 8, 'hidden_size': 20, 'hidden_size_two': 60, 'hidden_size_three': 30, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv2 {'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 64, 'hidden_size_three': 12, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv3 {'input_size': 8, 'hidden_size': 32, 'hidden_size_two': 128, 'hidden_size_three': 64, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv4 {'input_size': 8, 'hidden_size': 64, 'hidden_size_two': 64, 'hidden_size_three': 64, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv5 {'input_size': 8, 'hidden_size': 8, 'hidden_size_two': 64, 'hidden_size_three': 32, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv6 {'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 16, 'hidden_size_three': 16, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.001, 'batch_size': 2000000}\n",
      "MLv7 {'input_size': 8, 'hidden_size': 20, 'hidden_size_two': 60, 'hidden_size_three': 30, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2000000}\n",
      "MLv8 {'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 64, 'hidden_size_three': 12, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.01, 'batch_size': 2000000}\n",
      "MLv9 {'input_size': 8, 'hidden_size': 32, 'hidden_size_two': 128, 'hidden_size_three': 64, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.0012, 'batch_size': 2000000}\n",
      "MLv10 {'input_size': 8, 'hidden_size': 64, 'hidden_size_two': 64, 'hidden_size_three': 64, 'output_size': 1, 'num_epochs': 200, 'learning_rate': 0.0001, 'batch_size': 2000000}\n",
      "MLv11 {'input_size': 8, 'hidden_size': 8, 'hidden_size_two': 64, 'hidden_size_three': 32, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2000000}\n",
      "MLv12 {'input_size': 8, 'hidden_size': 16, 'hidden_size_two': 16, 'hidden_size_three': 16, 'output_size': 1, 'num_epochs': 100, 'learning_rate': 0.0015, 'batch_size': 2000000}\n"
     ]
    }
   ],
   "source": [
    "for param, name in zip(all_params, name_models):\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"ok\":true,\"result\":{\"message_id\":4985,\"from\":{\"id\":6231661874,\"is_bot\":true,\"first_name\":\"FutureAssistant\",\"username\":\"future_assistant_bot\"},\"chat\":{\"id\":463762417,\"first_name\":\"Konstantin\",\"username\":\"perky_psi\",\"type\":\"private\"},\"date\":1702499379,\"text\":\"\\\\u043c\\\\u043e\\\\u0434\\\\u0435\\\\u043b\\\\u044c: MLv1, \\\\u043f\\\\u043e\\\\u0433\\\\u0440\\\\u0435\\\\u0448\\\\u043d\\\\u043e\\\\u0441\\\\u0442\\\\u044c: 0.004124\"}}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from config import APIKEY\n",
    "name = 'MLv1'\n",
    "loss = 0.0041242356634161567143613461346134\n",
    "a = requests.get(f'https://api.telegram.org/bot{APIKEY}/sendMessage?chat_id=463762417&text=модель: {name}, погрешность: {loss:6f}')\n",
    "a.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

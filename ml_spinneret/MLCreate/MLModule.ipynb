{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, freeze_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size_two, hidden_size_three, output_size):\n",
    "        super(NNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size_two, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size_two, hidden_size_three, bias=True)\n",
    "        self.fc4 = nn.Linear(hidden_size_three, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_filename):\n",
    "    with open(dataset_filename, 'r') as file:\n",
    "        dataset = json.load(file)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "\n",
    "# Создаем объект логгера\n",
    "logger = logging.getLogger('MLModule')\n",
    "\n",
    "# Устанавливаем уровень логгирования для консольного логгера\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel('INFO')\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Устанавливаем уровень логгирования для файлового логгера\n",
    "file_handler = logging.FileHandler(f\"log-ml_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log\")\n",
    "file_handler.setLevel('DEBUG')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "nn_params = {\n",
    "    'input_size': 8,\n",
    "    'hidden_size': 8,\n",
    "    'hidden_size_two': 8,\n",
    "    'hidden_size_three': 8,\n",
    "    'output_size': 1,\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size':  256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Данные по модели\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model_name = 'MODEL_V_6.pth'\n",
    "nn_params = nn_params\n",
    "model = NNetwork(nn_params['input_size'], nn_params['hidden_size'], nn_params['hidden_size_two'],\n",
    "                            nn_params['hidden_size_three'], nn_params['output_size']).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=nn_params['learning_rate'])\n",
    "scaler_x = None\n",
    "scaler_y = None\n",
    "\n",
    "# Настройка датасета\n",
    "dataset_filename = 'DATASET.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:39:22,217 - INFO - Загрузка датасета ...\n",
      "2023-12-13 22:40:56,956 - INFO - Загрузка датасета завершена!\n"
     ]
    }
   ],
   "source": [
    "logger.info('Загрузка датасета ...')\n",
    "dataset = load_dataset(dataset_filename)\n",
    "logger.info('Загрузка датасета завершена!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:40:56,976 - INFO - Разбитие на samples\n",
      "100%|██████████| 31794210/31794210 [00:07<00:00, 4234267.58it/s]\n"
     ]
    }
   ],
   "source": [
    "all_outer_values = []\n",
    "all_central_values = []\n",
    "logger.info(f'Разбитие на samples')\n",
    "\n",
    "for item in tqdm(dataset):\n",
    "    all_outer_values.append(item['input'])\n",
    "    all_central_values.append(item['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:41:04,508 - INFO - Предобработка данных\n",
      "2023-12-13 22:41:27,751 - INFO - Нормализация данных\n",
      "2023-12-13 22:41:27,752 - INFO - Разбиение данных\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных\n",
    "logger.info('Предобработка данных')\n",
    "\n",
    "outer_x = np.array(all_outer_values, dtype=np.float32).T\n",
    "central_y = np.array(all_central_values, dtype=np.float32)\n",
    "\n",
    "outer_x = torch.tensor(all_outer_values, dtype=torch.float32)\n",
    "central_y = torch.tensor(all_central_values, dtype=torch.float32)\n",
    "\n",
    "X = outer_x.t()\n",
    "y = central_y.view(-1, 1)\n",
    "\n",
    "# Нормализация данных\n",
    "logger.info('Нормализация данных')\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Разделение данных на обучающий и тестовый наборы\n",
    "logger.info('Разбиение данных')\n",
    "X_train, X_test, y_train, y_test = train_test_split(outer_x, central_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразование данных в тензоры PyTorch\n",
    "if not torch.cuda.is_available():\n",
    "    X_train_scaled = torch.tensor(scaler_x.fit_transform(X_train), dtype=torch.float32).to('cuda')\n",
    "    y_train_scaled = torch.tensor(scaler_y.fit_transform(y_train.reshape(-1, 1)), dtype=torch.float32).to('cuda')\n",
    "\n",
    "    X_test_scaled = torch.tensor(scaler_x.transform(X_test), dtype=torch.float32).to('cuda')\n",
    "    y_test_scaled = torch.tensor(scaler_y.transform(y_test.reshape(-1, 1)), dtype=torch.float32).to('cuda')\n",
    "else:\n",
    "    X_train_scaled = torch.tensor(scaler_x.fit_transform(X_train), dtype=torch.float32)\n",
    "    y_train_scaled = torch.tensor(scaler_y.fit_transform(y_train.reshape(-1, 1)), dtype=torch.float32)\n",
    "\n",
    "    X_test_scaled = torch.tensor(scaler_x.transform(X_test), dtype=torch.float32)\n",
    "    y_test_scaled = torch.tensor(scaler_y.transform(y_test.reshape(-1, 1)), dtype=torch.float32)\n",
    "\n",
    "train_set = TensorDataset(X_train_scaled, y_train_scaled)\n",
    "test_set = TensorDataset(X_test_scaled, y_test_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=nn_params['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=nn_params['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступность CUDA: True\n",
      "Количество доступных устройств: 1\n",
      "Текущее устройство: 0\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Параметр fc1.weight на устройстве cpu\n",
      "Параметр fc1.bias на устройстве cpu\n",
      "Параметр fc2.weight на устройстве cpu\n",
      "Параметр fc2.bias на устройстве cpu\n",
      "Параметр fc3.weight на устройстве cpu\n",
      "Параметр fc3.bias на устройстве cpu\n",
      "Параметр fc4.weight на устройстве cpu\n",
      "Параметр fc4.bias на устройстве cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Доступность CUDA:\", torch.cuda.is_available())\n",
    "print(\"Количество доступных устройств:\", torch.cuda.device_count())\n",
    "print(\"Текущее устройство:\", torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Параметр {name} на устройстве {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:41:32,904 - INFO - Обучение сети\n",
      " 18%|█▊        | 17905/99357 [01:38<07:09, 189.78it/s]"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "logger.info('Обучение сети')\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    for epoch in range(nn_params['num_epochs']):\n",
    "        for batch_inp, batch_out in tqdm(train_loader):\n",
    "            model.train()\n",
    "\n",
    "            outputs = model(batch_inp)\n",
    "            loss = criterion(outputs, batch_out)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        logger.info(f'Epoch: {epoch}, Loss: {loss.item():.5f}')\n",
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 21:58:01,911 - INFO - Тестирование ...\n",
      "2023-12-13 21:58:01,911 - INFO - Тестирование ...\n",
      "2023-12-13 21:58:01,911 - INFO - Тестирование ...\n",
      "100%|██████████| 4/4 [00:38<00:00,  9.64s/it]\n",
      "2023-12-13 21:58:40,495 - INFO - Ошибка модели составляет: 0.285390 %\n",
      "Точность прогноза:  0.00%\n",
      "2023-12-13 21:58:40,495 - INFO - Ошибка модели составляет: 0.285390 %\n",
      "Точность прогноза:  0.00%\n",
      "2023-12-13 21:58:40,495 - INFO - Ошибка модели составляет: 0.285390 %\n",
      "Точность прогноза:  0.00%\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Тестирование модели\n",
    "logger.info(f'Тестирование ...')\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    final_loss = []\n",
    "    model.eval()\n",
    "    for batch_inp, batch_out in tqdm(test_loader):\n",
    "        outputs = model(batch_inp)\n",
    "        loss = criterion(outputs, batch_out)\n",
    "        final_loss.append(loss.item())\n",
    "print(prof)\n",
    "logger.info(f'Ошибка модели составляет: {np.mean(final_loss) * 100:5f} %\\nТочность прогноза: {final_accuracy * 100 / len(test_loader.dataset): .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "logger.info(f'Модель обучена, сохраняю модель в файл {model_name + \"_new\"}')\n",
    "checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                      'scaler_x_mean': scaler_x.mean_,\n",
    "                      'scaler_x_scale': scaler_x.scale_,\n",
    "                      'scaler_y_mean': scaler_y.mean_,\n",
    "                      'scaler_y_scale': scaler_y.scale_, }\n",
    "\n",
    "torch.save(checkpoint, model_name + \"_new\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
